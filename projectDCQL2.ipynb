{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.0 (SDL 2.0.12, python 3.7.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# window size\n",
    "WIDTH = 1060\n",
    "HEIGHT = 720\n",
    "FPS = 30 # how fast game is\n",
    "\n",
    "# colors\n",
    "WHITE = (255,255,255)\n",
    "BLACK = (0,0,0)\n",
    "RED = (255, 0, 0) # RGB\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "YELLOW = (255,255,0)\n",
    "\n",
    "IMGHISTORY = 4\n",
    "NBACTIONS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player(pygame.sprite.Sprite):\n",
    "    def __init__(self):\n",
    "        pygame.sprite.Sprite.__init__(self)\n",
    "        self.image = pygame.Surface((50,50))\n",
    "        self.image.fill(WHITE)\n",
    "     \n",
    "        self.rect = self.image.get_rect()\n",
    "        self.rect.centerx = 50\n",
    "        self.rect.centery = HEIGHT/2\n",
    "        \n",
    "        self.x_speed = 0\n",
    "        self.y_speed = 0\n",
    "        \n",
    "    def update(self,action):\n",
    "        # Controls\n",
    "        key_state = pygame.key.get_pressed()\n",
    "                \n",
    "        if key_state[pygame.K_w] or action == 0:\n",
    "            self.y_speed = -15\n",
    "            \n",
    "        elif key_state[pygame.K_s] or action == 1:\n",
    "            self.y_speed = 15\n",
    "        \n",
    "        elif key_state[pygame.K_a] or action == 2:\n",
    "            self.x_speed = -15\n",
    "            \n",
    "        elif key_state[pygame.K_d] or action == 3:\n",
    "            self.x_speed = 15\n",
    "            \n",
    "        \n",
    "        #Control update \n",
    "        self.rect.x += self.x_speed\n",
    "        self.rect.y += self.y_speed\n",
    "        \n",
    "        self.x_speed = 0\n",
    "        self.y_speed = 0\n",
    "        \n",
    "        #Screeen options\n",
    "        if self.rect.right > WIDTH:\n",
    "            self.rect.right = WIDTH\n",
    "            \n",
    "        if self.rect.left < 0:\n",
    "            self.rect.left = 0\n",
    "        \n",
    "        if self.rect.top < 0:\n",
    "            self.rect.top = 0\n",
    "        \n",
    "        if self.rect.bottom > HEIGHT:\n",
    "            self.rect.bottom = HEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enemy(pygame.sprite.Sprite):\n",
    "    def __init__(self):\n",
    "        pygame.sprite.Sprite.__init__(self)\n",
    "        self.image = pygame.Surface((40,40))\n",
    "        self.image.fill(RED)\n",
    "      \n",
    "        self.rect = self.image.get_rect()\n",
    "        self.y_center = random.randint(15,HEIGHT-10)\n",
    "        self.x_center = random.randint(WIDTH-400,WIDTH-20)\n",
    "        self.rect.center = (self.x_center,self.y_center)\n",
    "        \n",
    "        self.x_speed = -10\n",
    "        self.y_speed = 0\n",
    "             \n",
    "    def update(self):\n",
    "        self.rect.x += self.x_speed\n",
    "        \n",
    "        if self.rect.left < 0:\n",
    "            self.y_center = random.randint(15,HEIGHT-10)\n",
    "            self.x_center = random.randint(WIDTH-400,WIDTH-20)\n",
    "            self.rect.center = (self.x_center,self.y_center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self):\n",
    "        pygame.sprite.Sprite.__init__(self)\n",
    "        self.player_group = pygame.sprite.Group()\n",
    "        self.enemy_group = pygame.sprite.Group()\n",
    "        self.player = Player()\n",
    "        self.player_group.add(self.player)\n",
    "        #enemies\n",
    "        self.enemy_1 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_1)\n",
    "        self.enemy_2 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_2)\n",
    "        self.enemy_3 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_3)\n",
    "        self.enemy_4 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_4)        \n",
    "        self.enemy_5 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_5)\n",
    "        self.enemy_6 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_6)\n",
    "        self.enemy_7 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_7)\n",
    "        self.enemy_8 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_8)\n",
    "        self.enemy_9 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_9)\n",
    "        self.enemy_10 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_10)\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.total_reward = 0\n",
    "        self.done = False\n",
    "        self.agent = DQLAgent()\n",
    "    \n",
    "    def step(self,action):#PlayNextMove\n",
    "        \n",
    "        #update\n",
    "        self.player.update(action)\n",
    "        self.enemy_group.update()\n",
    "        \n",
    "        ScreenImage = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        \n",
    "        return ScreenImage \n",
    "    \n",
    "    def initialStates(self): #reset()\n",
    "        self.player_group = pygame.sprite.Group()\n",
    "        self.enemy_group = pygame.sprite.Group()\n",
    "        self.player = Player()\n",
    "        self.player_group.add(self.player)\n",
    "        #enemies\n",
    "        self.enemy_1 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_1)\n",
    "        self.enemy_2 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_2)\n",
    "        self.enemy_3 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_3)\n",
    "        self.enemy_4 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_4)        \n",
    "        self.enemy_5 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_5)\n",
    "        self.enemy_6 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_6)\n",
    "        self.enemy_7 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_7)\n",
    "        self.enemy_8 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_8)\n",
    "        self.enemy_9 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_9)\n",
    "        self.enemy_10 = Enemy()\n",
    "        self.enemy_group.add(self.enemy_10)\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.total_reward = 0\n",
    "        self.done = False\n",
    "        \n",
    "        #state\n",
    "        ScreenImage = pygame.surfarray.array3d(pygame.display.get_surface())\n",
    "        return ScreenImage \n",
    "    \n",
    "    def InitialDisplay(self):\n",
    "        \n",
    "        pygame.event.pump()\n",
    "        \n",
    "        #draw / render(show)\n",
    "        screen.fill(BLACK)\n",
    "        self.player_group.draw(screen)\n",
    "        self.enemy_group.draw(screen)\n",
    "\n",
    "        #after drawing flip display\n",
    "        pygame.display.flip()\n",
    "        \n",
    "    \n",
    "    def run(self):\n",
    "        # Game Loop\n",
    "        self.InitialDisplay()\n",
    "        batch_size = 16\n",
    "        running = True\n",
    "        \n",
    "        BestAction = 0\n",
    "        InitialScreenImage = self.step(BestAction)\n",
    "        InitialGameImage = ProcessGameImage(InitialScreenImage)\n",
    "        \n",
    "        GameState = np.stack((InitialGameImage,InitialGameImage,InitialGameImage,InitialGameImage),axis = 2)\n",
    "        GameState = GameState.reshape(1, GameState.shape[0],GameState.shape[1],GameState.shape[2])\n",
    "        \n",
    "        while running:\n",
    "            self.reward = 1\n",
    "            done = False\n",
    "            # keep loop running at the right speed\n",
    "            clock.tick(FPS)\n",
    "            \n",
    "            # process input\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    running = False\n",
    "\n",
    "            #update\n",
    "            BestAction = self.agent.act(GameState)\n",
    "            NewScreenImage = self.step(BestAction)\n",
    "            \n",
    "            NewGameImage = ProcessGameImage(NewScreenImage)\n",
    "            NewGameImage = NewGameImage.reshape(1,NewGameImage.shape[0],NewGameImage.shape[1],1)\n",
    "            \n",
    "            NextState = np.append(NewGameImage, GameState[:,:,:,:3], axis = 3)\n",
    "            self.agent.remember(GameState,BestAction,self.reward,NextState)\n",
    "            \n",
    "            self.total_reward += self.reward\n",
    "\n",
    "            # check to see if a enemy hit the player\n",
    "            hits = pygame.sprite.spritecollide(self.player, self.enemy_group, False)\n",
    "            if hits: #hits == True\n",
    "                self.reward = -400\n",
    "                self.total_reward += self.reward\n",
    "                self.done = True\n",
    "                running = False\n",
    "                print(\"Total Reward: \", self.total_reward)\n",
    "                self.initialStates()\n",
    "            \n",
    "             # training\n",
    "            self.agent.replay(batch_size,done)\n",
    "            \n",
    "            # update state\n",
    "            GameState = NextState\n",
    "            \n",
    "            # epsilon greedy\n",
    "            self.agent.adaptiveEGreedy()                       \n",
    "                \n",
    "            #draw / render(show)\n",
    "            screen.fill(BLACK)\n",
    "            self.player_group.draw(screen)\n",
    "            self.enemy_group.draw(screen)\n",
    "\n",
    "            #after drawing flip display\n",
    "            pygame.display.flip()\n",
    "                    \n",
    "        pygame.quit()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQLAgent:\n",
    "    def __init__(self):\n",
    "        # parameter / hyperparameter\n",
    "        self.action_size = 4\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.learning_rate = 0.001 \n",
    "        \n",
    "        self.epsilon = 1  # explore\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.01\n",
    "        \n",
    "        self.memory = deque(maxlen = 3000) \n",
    "        \n",
    "        self.model = self.build_model()\n",
    "        \n",
    "        \n",
    "    def build_model(self):\n",
    "        # neural network for deep q learning\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=4, strides = (2,2), input_shape = (IMGHEIGHT,IMGWIDTH,IMGHISTORY),padding = \"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64,kernel_size=4,strides=(2,2),padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64,kernel_size=3,strides=(1,1),padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(units= NBACTIONS, activation=\"linear\"))\n",
    "        \n",
    "        model.compile(loss = \"mse\", optimizer=\"adam\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state): # (CaptureSample)\n",
    "        # storage\n",
    "        self.memory.append((state, action, reward, next_state))\n",
    "    \n",
    "    def act(self, state):\n",
    "        state = np.array(state)\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def replay(self, batch_size,done):\n",
    "        # training\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory,batch_size)\n",
    "        \n",
    "        inputs = np.zeros((batch_size,IMGHEIGHT,IMGWIDTH,IMGHISTORY))\n",
    "        targets = np.zeros((inputs.shape[0],NBACTIONS))\n",
    "        Q_sa = 0\n",
    "        \n",
    "        for i in range(len(minibatch)):\n",
    "            state = minibatch[i][0]\n",
    "            action = minibatch[i][1]\n",
    "            reward = minibatch[i][2]\n",
    "            next_state = minibatch[i][3]\n",
    "            \n",
    "            inputs[i:i + 1] = state\n",
    "            targets[i]  = self.model.predict(state)\n",
    "            Q_sa = self.model.predict(next_state)\n",
    "            \n",
    "            if done:\n",
    "                targets[i,action] = reward\n",
    "            else:\n",
    "                targets[i,action] = reward + self.gamma*np.max(Q_sa)\n",
    "                \n",
    "            self.model.fit(inputs, targets ,batch_size= batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "    def adaptiveEGreedy(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage as skimage\n",
    "import warnings\n",
    "import skimage.color\n",
    "from skimage.transform import resize\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGHEIGHT = 40\n",
    "IMGWIDTH = 40\n",
    "IMGHISTORY = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessGameImage(RawImage):\n",
    "    \n",
    "    GreyImage = skimage.color.rgb2gray(RawImage)\n",
    "    \n",
    "    CroppedImage = GreyImage[0:HEIGHT,0:WIDTH]\n",
    "    \n",
    "    ReducedImage = skimage.transform.resize(CroppedImage,(IMGHEIGHT,IMGWIDTH))\n",
    "    \n",
    "    ReducedImage = skimage.exposure.rescale_intensity(ReducedImage, out_range = (0,255))\n",
    "    \n",
    "    ReducedImage = ReducedImage / 128\n",
    "    \n",
    "    return ReducedImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    env = Env()\n",
    "    liste = []\n",
    "    t = 0\n",
    "    while True:\n",
    "        t += 1\n",
    "        print(\"Episode:\",t)\n",
    "        liste.append(env.total_reward)\n",
    "        \n",
    "        # initialize pygame and create window\n",
    "        pygame.init()\n",
    "        screen = pygame.display.set_mode((WIDTH,HEIGHT))\n",
    "        pygame.display.set_caption(\"kacma oyunu\")\n",
    "        clock = pygame.time.Clock()\n",
    "        \n",
    "        env.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
